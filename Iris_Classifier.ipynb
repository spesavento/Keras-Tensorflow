{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs through a simple classification example using everyone's FAVORITE dataset: the Iris datasert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To download after getting Anaconda, run: conda install keras\n",
    "#For sklearn --> conda install scikit-learn=0.18\n",
    "import numpy as np\n",
    "import pandas\n",
    "import sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.2\n"
     ]
    }
   ],
   "source": [
    "#If erroring check sklearn version\n",
    "import sklearn\n",
    "print (sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a seed. This allows the code to be reproduced. Note: np = numpy \n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset. Use the path from your working directory to where your file is located\n",
    "dataframe = pandas.read_csv(\"/Users/sarapesavento/Desktop/iris/iris.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "X = dataset[:,0:4].astype(float)\n",
    "Y = dataset[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"One hot encoding\" is creating dummy variables from a categorical variable (e.g. Iris flower type) \n",
    "<pre>\n",
    "setosa  versicolor  virginica\n",
    "1       0           0 \n",
    "0       1           0\n",
    "0       0           1\n",
    "</pre>\n",
    "\n",
    "\n",
    "To do this you can encode the strings to integers and then make the integers one hot encoded using to_categorical()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# Convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create a neural network model to train. This can be defined with the following model. The structure is: <p>\n",
    "\\# inputs -> [(hidden layer 1 with) # nodes] --> # outputs <p>\n",
    "For this example: the 4 for plant dimensions are the input,  with which we hope to get the correct plant classification back. The outputs are the 3 plant types. This basic structure can be coded using the Adam gradient descent optimization algorithm. It uses a “softmax” activation function in the output to ensure results are from 0 to 1 (gives the probability of input being a certain plant type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #dense layer is simply a layer where each unit or neuron is connected to each neuron in the next layer\n",
    "    model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to run the model using the KerasClassifier.\n",
    "KerasClassifier(build_fn = function_name, epochs=#times you go through your training set, batch_size=#of batches to split whole data into to be run through, verbose=0/1 whether or not you want debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate The Model with k-Fold Cross Validation. k-fold cross validation involves randomly dividing the training set into k groups, or folds, of approximately equal size. The first fold is treated as a validation set, and the method is fit on the remaining k−1 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
